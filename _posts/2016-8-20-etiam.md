---
layout: post
title: Etiam
description: Feugiat amet tempus
image: assets/images/pic06.jpg
---

# Detectron 2 Mask R-CNN R50-FPN 3x to TensorRT

**If you dont want to do setup part as mentioned from step `1. Build Container`**

**Pull these ready-made container** 

**Container 1** -  only for .pt  to .onnx conversion (step1)

	docker pull supatel001213/detectron-trt-conversion:v3-part1

**Container 2** -  converting `model.onnx` to `converted.onnx` (step 2) and trt conversion (step 3)

	docker pull supatel001213/detectron-trt-conversion:v3-part2

# 2. Conversion

# 2.0 Add classes to the yaml file  | In Container 1
file location: `/workspace/detectron2/configs/Base-RCNN-FPN.yaml`
```yaml
  ROI_HEADS:
    NAME: "StandardROIHeads"
    IN_FEATURES: ["p2", "p3", "p4", "p5"]
    NUM_CLASSES: 46
```  

## 2.1 To onnx  | In Container 1

```bash
cd /workspace/detectron2/tools/deploy/

python export_model.py \
    --sample-image /maskRCNN/model_dummy_1344x1344/1344x1344_export_img.jpg \
    --config-file /workspace/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml \
    --export-method caffe2_tracing \
    --format onnx \
    --output /maskRCNN/model_dummy_1344x1344 \
    MODEL.WEIGHTS /workspace/model_dummy_1344x1344/dummy_maskrcnn_model_dummy_wt_random.pth \
    MODEL.DEVICE cuda

```
Please change the path according to your directory structure.

## 2.2 Optimize ONNX to TRT friendly graph | In Container 2

```bash
cd /workspace/detectron2trt/

python create_onnx.py \
    --exported_onnx /rift/model_dummy_1344x1344/model.onnx \
    --onnx /rift/model_dummy_1344x1344/converted_new.onnx \
    --det2_config /workspace/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml \
    --det2_weights /rift/model_dummy_1344x1344/dummy_maskrcnn_model_dummy_wt_random.pth \
    --sample_image /rift/model_dummy_1344x1344/1344x1344_export_img.jpg
```
Please change the model path, image path and output path.

## 2.3 Convert ONNX to TRT | In Container 2

```bash
cd /rift/model_dummy_1344x1344/
trtexec --onnx=converted_new.onnx --saveEngine=converted_new.trt --useCudaGraph
```
Please change the path according to your directory structure.


## 2.4 Eval

It will require coco eval annotation set  at `/workspace/oss/samples/python/detectron2/datasets/coco/annotations`
It will require  coco eval images at `/workspace/detectron2/datasets/coco/temp/val2017`

```bash
cd /workspace/oss/samples/python/detectron2/eval.sh
python eval_coco.py \
    --engine /workspace/model_1344x1344/engine.trt \
    --input /workspace/detectron2/datasets/coco/temp/val2017 \
    --det2_config /workspace/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml \
    --det2_weights /workspace/detectron2/model/model_final_f10217.pkl
```
This will compare accuracy after conversion w.r.t coco eval set

### 2.4.1 Accuracy analysis  -  OLD

```
root@nvidia-DGX-Station:/workspace/oss/samples/python/detectron2# bash eval.sh 
Loading and preparing results...
##############################Original Model
DONE (t=0.21s)
creating index...
index created!
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.614
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.440
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.247
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.515
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.511
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665
##############################Converted Model
Loading and preparing results...
DONE (t=2.39s)
creating index...
index created!
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.585
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.395
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.305
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.472
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634
```
Please change the path according to your directory structure.
## 2.5 Visual analysis

```
python infer.py \
    --engine /workspace/model_1344x1344/engine.trt \
    --input /workspace/detectron2/datasets/coco/val2017/ \
    --det2_config /workspace/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml \
    --output /workspace/TRT_output/FP32/ \
    --nms_threshold 0.5
```
Please change the path according to your directory structure.
# 3. Performance Analysis

| Model                    | Batch size | Compute time - Min (ms) | Compute time - Max (ms) | Query Per Second (QPS) | VRAM util. |
| ------------------------ | ---------- | ----------------------- | ----------------------- | ---------------------- | ---------- |
| Resnet 1344X1344 FP32    | 1          | 51.6936                 | 52.6797                 | 18.8426                | 2-3 GB     |
| Resnet 1344X1344 FP16    | 1          | 28.7988                 | 29.231                  | 34.1791                | 2-3 GB     |
| Resnet 834X1344 FP32     | 1          | 31.6345                 | 32.2253                 | 31.0546                | 2-3 GB     |
| **Resnet 834X1344 FP16** | **1**      | **11.3049**             | **11.8354**             | **87.4432**            | **2-3 GB** |
| Resnet 834X1344 FP32     | 4          | 123.545                 | 125.398                 | 7.74789                | 4-5 GB     |
| Resnet 834X1344 FP16     | 4          | 39.8613                 | 41.3768                 | 24.6119                | 4-5 GB     |

**Customer's model**

| Model             | Batch size | Compute time - Min (ms) | Compute time - Max (ms) | Query Per Second (QPS) | VRAM util. |
| ----------------- | ---------- | ----------------------- | ----------------------- | ---------------------- | ---------- |
| Resnet ??X?? FP32 | 1          |                         |                         | ?? fps                 |            |

## Size 1344X1344 FP32
### log

```
[05/12/2022-07:57:13] [I] === Performance summary === 
[05/12/2022-07:57:13] [I] Throughput: 18.8426 qps 
[05/12/2022-07:57:13] [I] Latency: min = 53.5979 ms, max = 54.5764 ms, mean = 54.1174 ms, median = 54.1216 ms, percentile(99%) = 54.5764 ms 
[05/12/2022-07:57:13] [I] End-to-End Host Latency: min = 101.093 ms, max = 105.217 ms, mean = 104.144 ms, median = 104.345 ms, percentile(99%) = 105.217 ms 
[05/12/2022-07:57:13] [I] Enqueue Time: min = 0.0549164 ms, max = 0.189941 ms, mean = 0.0990306 ms, median = 0.0963745 ms, percentile(99%) = 0.189941 ms 
[05/12/2022-07:57:13] [I] H2D Latency: min = 1.80585 ms, max = 1.88464 ms, mean = 1.86223 ms, median = 1.86591 ms, percentile(99%) = 1.88464 ms 
[05/12/2022-07:57:13] [I] GPU Compute Time: min = 51.6936 ms, max = 52.6797 ms, mean = 52.205 ms, median = 52.1959 ms, percentile(99%) = 52.6797 ms 
[05/12/2022-07:57:13] [I] D2H Latency: min = 0.0351562 ms, max = 0.0545654 ms, mean = 0.0501617 ms, median = 0.0500793 ms, percentile(99%) = 0.0545654 ms 
[05/12/2022-07:57:13] [I] Total Host Walltime: 3.18428 s 
[05/12/2022-07:57:13] [I] Total GPU Compute Time: 3.1323 s 
[05/12/2022-07:57:13] [I] Explanations of the performance metrics are printed in the verbose logs. 
[05/12/2022-07:57:13] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8201] # trtexec --onnx=converted.onnx --saveEngine=engine.trt --useCudaGraph 
```



## Size 1344X1344 FP16

### log

```
trtexec --onnx=converted.onnx --saveEngine=engine.trt --useCudaGraph --fp16 
[05/12/2022-08:06:42] [I] === Performance summary === 
[05/12/2022-08:06:42] [I] Throughput: 34.1791 qps 
[05/12/2022-08:06:42] [I] Latency: min = 30.7014 ms, max = 31.1367 ms, mean = 30.8894 ms, median = 30.8977 ms, percentile(99%) = 31.017 ms 
[05/12/2022-08:06:42] [I] End-to-End Host Latency: min = 56.7634 ms, max = 58.2302 ms, mean = 57.862 ms, median = 57.8794 ms, percentile(99%) = 58.2173 ms 
[05/12/2022-08:06:42] [I] Enqueue Time: min = 0.0693359 ms, max = 0.201172 ms, mean = 0.103305 ms, median = 0.104057 ms, percentile(99%) = 0.19281 ms 
[05/12/2022-08:06:42] [I] H2D Latency: min = 1.84137 ms, max = 1.88123 ms, mean = 1.85902 ms, median = 1.85901 ms, percentile(99%) = 1.87494 ms 
[05/12/2022-08:06:42] [I] GPU Compute Time: min = 28.7988 ms, max = 29.231 ms, mean = 28.9806 ms, median = 28.9858 ms, percentile(99%) = 29.1 ms 
[05/12/2022-08:06:42] [I] D2H Latency: min = 0.0354004 ms, max = 0.0548706 ms, mean = 0.0498256 ms, median = 0.0500488 ms, percentile(99%) = 0.0539551 ms 
[05/12/2022-08:06:42] [I] Total Host Walltime: 3.10131 s 
[05/12/2022-08:06:42] [I] Total GPU Compute Time: 3.07194 s 
[05/12/2022-08:06:42] [I] Explanations of the performance metrics are printed in the verbose logs. 
[05/12/2022-08:06:42] [I] 
```

## Size 832X1344 FP32

### log

```
trtexec --onnx=converted_832x1344.onnx --saveEngine=engine_832x1344.trt --useCudaGraph 
[05/12/2022-11:16:28] [I] === Performance summary === 
[05/12/2022-11:16:28] [I] Throughput: 31.0546 qps 
[05/12/2022-11:16:28] [I] Latency: min = 32.835 ms, max = 33.4138 ms, mean = 33.0683 ms, median = 33.0688 ms, percentile(99%) = 33.4138 ms 
[05/12/2022-11:16:28] [I] End-to-End Host Latency: min = 48.3713 ms, max = 64.3342 ms, mean = 63.1113 ms, median = 63.6342 ms, percentile(99%) = 64.3342 ms 
[05/12/2022-11:16:28] [I] Enqueue Time: min = 0.0668945 ms, max = 0.176514 ms, mean = 0.0943542 ms, median = 0.0936279 ms, percentile(99%) = 0.176514 ms 
[05/12/2022-11:16:28] [I] H2D Latency: min = 1.14355 ms, max = 1.18945 ms, mean = 1.16311 ms, median = 1.16246 ms, percentile(99%) = 1.18945 ms 
[05/12/2022-11:16:28] [I] GPU Compute Time: min = 31.6345 ms, max = 32.2253 ms, mean = 31.8639 ms, median = 31.8628 ms, percentile(99%) = 32.2253 ms 
[05/12/2022-11:16:28] [I] D2H Latency: min = 0.0351562 ms, max = 0.045166 ms, mean = 0.0412833 ms, median = 0.0415649 ms, percentile(99%) = 0.045166 ms 
[05/12/2022-11:16:28] [I] Total Host Walltime: 3.09133 s 
[05/12/2022-11:16:28] [I] Total GPU Compute Time: 3.05894 s 
[05/12/2022-11:16:28] [I] Explanations of the performance metrics are printed in the verbose logs. 
[05/12/2022-11:16:28] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8201] # trtexec --onnx=converted_832x1344.onnx --saveEngine=engine_832x1344.trt --useCudaGraph 
```


## Size 832X1344 FP16

### log

```
trtexec --onnx=converted_832x1344.onnx --saveEngine=engine_832x1344_16.trt --useCudaGraph â€“fp16 
[05/12/2022-11:13:36] [I] === Performance summary === 
[05/12/2022-11:13:36] [I] Throughput: 87.4432 qps 
[05/12/2022-11:13:36] [I] Latency: min = 12.4919 ms, max = 13.0096 ms, mean = 12.5484 ms, median = 12.5322 ms, percentile(99%) = 13.0023 ms 
[05/12/2022-11:13:36] [I] End-to-End Host Latency: min = 12.6115 ms, max = 23.7008 ms, mean = 22.5418 ms, median = 22.616 ms, percentile(99%) = 23.5767 ms 
[05/12/2022-11:13:36] [I] Enqueue Time: min = 0.0623169 ms, max = 0.192749 ms, mean = 0.0972623 ms, median = 0.0935059 ms, percentile(99%) = 0.15918 ms 
[05/12/2022-11:13:36] [I] H2D Latency: min = 1.12061 ms, max = 1.1723 ms, mean = 1.14873 ms, median = 1.14813 ms, percentile(99%) = 1.17102 ms 
[05/12/2022-11:13:36] [I] GPU Compute Time: min = 11.3049 ms, max = 11.8354 ms, mean = 11.359 ms, median = 11.3387 ms, percentile(99%) = 11.8211 ms 
[05/12/2022-11:13:36] [I] D2H Latency: min = 0.03479 ms, max = 0.0549927 ms, mean = 0.0406325 ms, median = 0.039978 ms, percentile(99%) = 0.0532227 ms 
[05/12/2022-11:13:36] [I] Total Host Walltime: 3.03054 s 
[05/12/2022-11:13:36] [I] Total GPU Compute Time: 3.01014 s 
[05/12/2022-11:13:36] [I] Explanations of the performance metrics are printed in the verbose logs. 
[05/12/2022-11:13:36] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8201] # trtexec --onnx=converted_832x1344.onnx --saveEngine=engine_832x1344_16.trt --useCudaGraph --fp16 
```

## Size 832X1344 FP32 Batchsize =4

### log

```
[05/12/2022-12:25:31] [I] === Trace details ===
[05/12/2022-12:25:31] [I] Trace averages of 10 runs:
[05/12/2022-12:25:31] [I] Average on 10 runs - GPU latency: 124.469 ms - Host latency: 129.308 ms (end to end 248.441 ms, enqueue 0.106811 ms)
[05/12/2022-12:25:31] [I] Average on 10 runs - GPU latency: 124.324 ms - Host latency: 129.098 ms (end to end 248.148 ms, enqueue 0.122681 ms)
[05/12/2022-12:25:31] [I] 
[05/12/2022-12:25:31] [I] === Performance summary ===
[05/12/2022-12:25:31] [I] Throughput: 7.74789 qps
[05/12/2022-12:25:31] [I] Latency: min = 128.326 ms, max = 130.564 ms, mean = 129.138 ms, median = 129.01 ms, percentile(99%) = 130.564 ms
[05/12/2022-12:25:31] [I] End-to-End Host Latency: min = 243.737 ms, max = 250.369 ms, mean = 248.224 ms, median = 248.092 ms, percentile(99%) = 250.369 ms
[05/12/2022-12:25:31] [I] Enqueue Time: min = 0.0583267 ms, max = 0.185791 ms, mean = 0.121948 ms, median = 0.119446 ms, percentile(99%) = 0.185791 ms
[05/12/2022-12:25:31] [I] H2D Latency: min = 4.5907 ms, max = 5.34836 ms, mean = 4.6555 ms, median = 4.63173 ms, percentile(99%) = 5.34836 ms
[05/12/2022-12:25:31] [I] GPU Compute Time: min = 123.545 ms, max = 125.398 ms, mean = 124.339 ms, median = 124.235 ms, percentile(99%) = 125.398 ms
[05/12/2022-12:25:31] [I] D2H Latency: min = 0.108154 ms, max = 0.150543 ms, mean = 0.143057 ms, median = 0.143982 ms, percentile(99%) = 0.150543 ms
[05/12/2022-12:25:31] [I] Total Host Walltime: 3.35575 s
[05/12/2022-12:25:31] [I] Total GPU Compute Time: 3.23283 s
[05/12/2022-12:25:31] [I] Explanations of the performance metrics are printed in the verbose logs.
[05/12/2022-12:25:31] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8201] # trtexec --onnx=converted_832x1344_batch4.onnx --saveEngine=engine_832x1344_batch4.trt --useCudaGraph --workspace=100
```


## Size 832X1344 FP16 Batchsize =4

### log

```
[05/12/2022-12:32:07] [I] Trace averages of 10 runs:
[05/12/2022-12:32:07] [I] Average on 10 runs - GPU latency: 40.7541 ms - Host latency: 45.4278 ms (end to end 80.0033 ms, enqueue 0.104922 ms)
[05/12/2022-12:32:07] [I] Average on 10 runs - GPU latency: 40.0342 ms - Host latency: 44.7346 ms (end to end 77.8458 ms, enqueue 0.10069 ms)
[05/12/2022-12:32:07] [I] Average on 10 runs - GPU latency: 39.9712 ms - Host latency: 44.7026 ms (end to end 79.8355 ms, enqueue 0.111823 ms)
[05/12/2022-12:32:07] [I] Average on 10 runs - GPU latency: 39.9623 ms - Host latency: 44.6922 ms (end to end 79.8164 ms, enqueue 0.111951 ms)
[05/12/2022-12:32:07] [I] Average on 10 runs - GPU latency: 39.9767 ms - Host latency: 44.7099 ms (end to end 79.8401 ms, enqueue 0.137085 ms)
[05/12/2022-12:32:07] [I] Average on 10 runs - GPU latency: 39.9665 ms - Host latency: 44.6919 ms (end to end 79.8324 ms, enqueue 0.110254 ms)
[05/12/2022-12:32:07] [I] Average on 10 runs - GPU latency: 39.9653 ms - Host latency: 44.6897 ms (end to end 79.8297 ms, enqueue 0.102124 ms)
[05/12/2022-12:32:07] [I] 
[05/12/2022-12:32:07] [I] === Performance summary ===
[05/12/2022-12:32:07] [I] Throughput: 24.6119 qps
[05/12/2022-12:32:07] [I] Latency: min = 44.5459 ms, max = 46.002 ms, mean = 44.7953 ms, median = 44.7021 ms, percentile(99%) = 46.002 ms
[05/12/2022-12:32:07] [I] End-to-End Host Latency: min = 62.2874 ms, max = 83.7024 ms, mean = 79.595 ms, median = 79.8391 ms, percentile(99%) = 83.7024 ms
[05/12/2022-12:32:07] [I] Enqueue Time: min = 0.0782776 ms, max = 0.238525 ms, mean = 0.110144 ms, median = 0.108215 ms, percentile(99%) = 0.238525 ms
[05/12/2022-12:32:07] [I] H2D Latency: min = 4.46893 ms, max = 4.63184 ms, mean = 4.57512 ms, median = 4.58105 ms, percentile(99%) = 4.63184 ms
[05/12/2022-12:32:07] [I] GPU Compute Time: min = 39.8613 ms, max = 41.3768 ms, mean = 40.0779 ms, median = 39.9749 ms, percentile(99%) = 41.3768 ms
[05/12/2022-12:32:07] [I] D2H Latency: min = 0.108398 ms, max = 0.154907 ms, mean = 0.142334 ms, median = 0.142578 ms, percentile(99%) = 0.154907 ms
[05/12/2022-12:32:07] [I] Total Host Walltime: 3.12857 s
[05/12/2022-12:32:07] [I] Total GPU Compute Time: 3.086 s
[05/12/2022-12:32:07] [I] Explanations of the performance metrics are printed in the verbose logs.
[05/12/2022-12:32:07] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8201] # trtexec --onnx=converted_832x1344_batch4.onnx --saveEngine=engine_832x1344_batch4.trt --useCudaGraph --fp16 --workspace=100
```


# Conversion Logs
```bash
root@nvidia-DGX-Station:/workspace/detectron2/tools/deploy# bash to_onnx.sh
[07/26 11:43:02 detectron2]: Command line arguments: Namespace(config_file='/workspace/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', export_method='caffe2_tracing', format='onnx', opts=['MODEL.WEIGHTS', '/workspace/model_dummy_1344x1344/dummy_maskrcnn_model_dummy_wt_random.pth', 'MODEL.DEVICE', 'cuda'], output='/maskRCNN/model_dummy_1344x1344', run_eval=False, sample_image='/maskRCNN/model_dummy_1344x1344/1344x1344_export_img.jpg')
[07/26 11:43:07 d2.checkpoint.c2_model_loading]: Following weights matched with model:
| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |
|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|
| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |
| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |
| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |
| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |
| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |
| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |
| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |
| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |
| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (184,) (184,1024)                               |
| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (47,) (47,1024)                                 |
| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                             | (256,) (256,256,2,2)                            |
| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{bias,weight}                                                          | (256,) (256,256,3,3)                            |
| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{bias,weight}                                                          | (256,) (256,256,3,3)                            |
| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{bias,weight}                                                          | (256,) (256,256,3,3)                            |
| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{bias,weight}                                                          | (256,) (256,256,3,3)                            |
| roi_heads.mask_head.predictor.*                 | roi_heads.mask_head.predictor.{bias,weight}                                                          | (46,) (46,256,1,1)                              |
/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:267: UserWarning: `add_node_names' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `add_node_names` argument will be ignored.
  warnings.warn("`{}' can be set to True only when 'operator_export_type' is "
/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:267: UserWarning: `do_constant_folding' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `do_constant_folding` argument will be ignored.
  warnings.warn("`{}' can be set to True only when 'operator_export_type' is "
/usr/local/lib/python3.8/dist-packages/detectron2/export/c10.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert tensor.dim() == 2 and tensor.size(-1) in [4, 5, 6], tensor.size()
/usr/local/lib/python3.8/dist-packages/detectron2/export/c10.py:392: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if num_classes + 1 == class_logits.shape[1]:
/usr/local/lib/python3.8/dist-packages/detectron2/export/c10.py:401: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert box_regression.shape[1] % box_dim == 0
/usr/local/lib/python3.8/dist-packages/detectron2/export/c10.py:402: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  cls_agnostic_bbox_reg = box_regression.shape[1] // box_dim == 1
/usr/local/lib/python3.8/dist-packages/detectron2/export/c10.py:408: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if input_tensor_mode:
/usr/local/lib/python3.8/dist-packages/detectron2/export/c10.py:440: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  nms_outputs = torch.ops._caffe2.BoxWithNMSLimit(
/usr/local/lib/python3.8/dist-packages/detectron2/export/c10.py:469: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  for i, b in enumerate(int(x.item()) for x in roi_batch_splits_nms)
/usr/local/lib/python3.8/dist-packages/detectron2/export/c10.py:469: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  for i, b in enumerate(int(x.item()) for x in roi_batch_splits_nms)
/usr/local/lib/python3.8/dist-packages/detectron2/export/c10.py:76: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  data_len = len(value)
/usr/local/lib/python3.8/dist-packages/detectron2/export/c10.py:95: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  return len(self.indices)
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::ResizeNearest type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::ResizeNearest type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::ResizeNearest type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CollectRpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BatchPermutation type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BBoxTransform type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BBoxTransform type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BatchPermutation type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::ResizeNearest type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::ResizeNearest type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::ResizeNearest type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::GenerateProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CollectRpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BatchPermutation type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BBoxTransform type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BBoxTransform type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BoxWithNMSLimit type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyGPUToCPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::DistributeFpnProposals type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::CopyCPUToGPU type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::RoIAlign type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::BatchPermutation type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of _caffe2::AliasWithName type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: ONNX Optimizer has been moved to https://github.com/onnx/optimizer.
All further enhancements and fixes to optimizers will be done in this new repo.
The optimizer code in onnx/onnx repo will be removed in 1.9 release.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

root@nvidia-DGX-Station:/workspace/detectron2trt# bash to_converted.sh 
INFO:ModelHelper:ONNX graph loaded successfully
INFO:ModelHelper:Number of FPN output channels is 256
INFO:ModelHelper:Number of classes is 46
INFO:ModelHelper:First NMS max proposals is 1000
INFO:ModelHelper:First NMS iou threshold is 0.7
INFO:ModelHelper:First NMS score threshold is 0.01
INFO:ModelHelper:First ROIAlign type is ROIAlignV2
INFO:ModelHelper:First ROIAlign pooled size is 7
INFO:ModelHelper:First ROIAlign sampling ratio is 0
INFO:ModelHelper:Second NMS max proposals is 100
INFO:ModelHelper:Second NMS iou threshold is 0.5
INFO:ModelHelper:Second NMS score threshold is 0.05
INFO:ModelHelper:Second ROIAlign type is ROIAlignV2
INFO:ModelHelper:Second ROIAlign pooled size is 14
INFO:ModelHelper:Second ROIAlign sampling ratio is 0
INFO:ModelHelper:Individual mask output resolution is 28x28
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CollectRpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator DistributeFpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator BatchPermutation. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator BBoxTransform. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator BoxWithNMSLimit. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator DistributeFpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator BatchPermutation. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CollectRpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator DistributeFpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator BatchPermutation. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator BBoxTransform. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator BoxWithNMSLimit. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator DistributeFpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator BatchPermutation. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
INFO:ModelHelper:ONNX graph input shape: [1, 3, 1344, 1344] [NCHW format set]
INFO:ModelHelper:Found Sub node
INFO:ModelHelper:Found Div node
INFO:ModelHelper:Found Conv node
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CollectRpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator DistributeFpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator BatchPermutation. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator BBoxTransform. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator BoxWithNMSLimit. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator DistributeFpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator BatchPermutation. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator GenerateProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CollectRpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator DistributeFpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator BatchPermutation. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator BBoxTransform. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator BoxWithNMSLimit. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
Warning: Unsupported operator CopyGPUToCPU. No schema registered for this operator.
Warning: Unsupported operator DistributeFpnProposals. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator CopyCPUToGPU. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator RoIAlign. No schema registered for this operator.
Warning: Unsupported operator BatchPermutation. No schema registered for this operator.
Warning: Unsupported operator AliasWithName. No schema registered for this operator.
INFO:fvcore.common.checkpoint:[Checkpointer] Loading from /rift/model_dummy_1344x1344/dummy_maskrcnn_model_dummy_wt_random.pth ...
INFO:detectron2.checkpoint.c2_model_loading:Following weights matched with model:
| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |
|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|
| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |
| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |
| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |
| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |
| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |
| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |
| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |
| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |
| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (184,) (184,1024)                               |
| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (47,) (47,1024)                                 |
| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                             | (256,) (256,256,2,2)                            |
| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{bias,weight}                                                          | (256,) (256,256,3,3)                            |
| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{bias,weight}                                                          | (256,) (256,256,3,3)                            |
| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{bias,weight}                                                          | (256,) (256,256,3,3)                            |
| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{bias,weight}                                                          | (256,) (256,256,3,3)                            |
| roi_heads.mask_head.predictor.*                 | roi_heads.mask_head.predictor.{bias,weight}                                                          | (46,) (46,256,1,1)                              |
/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
INFO:ModelHelper:Created first ResizeNearest_TRT plugin
INFO:ModelHelper:Created second ResizeNearest_TRT plugin
INFO:ModelHelper:Created third ResizeNearest_TRT plugin
INFO:ModelHelper:Created nms_rpn with EfficientNMS_TRT plugin
INFO:ModelHelper:Created box_pooler with PyramidROIAlign_TRT plugin
INFO:ModelHelper:Created nms_box_outputs with EfficientNMS_TRT plugin
INFO:ModelHelper:Created mask_pooler with PyramidROIAlign_TRT plugin
Warning: Unsupported operator ResizeNearest_TRT. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest_TRT. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest_TRT. No schema registered for this operator.
Warning: Unsupported operator EfficientNMS_TRT. No schema registered for this operator.
Warning: Unsupported operator PyramidROIAlign_TRT. No schema registered for this operator.
Warning: Unsupported operator EfficientNMS_TRT. No schema registered for this operator.
Warning: Unsupported operator PyramidROIAlign_TRT. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest_TRT. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest_TRT. No schema registered for this operator.
Warning: Unsupported operator ResizeNearest_TRT. No schema registered for this operator.
Warning: Unsupported operator EfficientNMS_TRT. No schema registered for this operator.
Warning: Unsupported operator PyramidROIAlign_TRT. No schema registered for this operator.
Warning: Unsupported operator EfficientNMS_TRT. No schema registered for this operator.
Warning: Unsupported operator PyramidROIAlign_TRT. No schema registered for this operator.
INFO:ModelHelper:Saved ONNX model to /rift/model_dummy_1344x1344/converted_new.onnx
root@nvidia-DGX-Station:/workspace/detectron2trt# 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


root@nvidia-DGX-Station:/rift/model_dummy_1344x1344# ls
1344x1344_export_img.jpg  converted_new.onnx  dummy_maskrcnn_model_dummy_wt_random.pth  model.onnx
root@nvidia-DGX-Station:/rift/model_dummy_1344x1344# trtexec --onnx=converted_new.onnx --saveEngine=converted_new.trt --useCudaGraph 
&&&& RUNNING TensorRT.trtexec [TensorRT v8401] # trtexec --onnx=converted_new.onnx --saveEngine=converted_new.trt --useCudaGraph
[07/26/2022-11:52:06] [I] === Model Options ===
[07/26/2022-11:52:06] [I] Format: ONNX
[07/26/2022-11:52:06] [I] Model: converted_new.onnx
[07/26/2022-11:52:06] [I] Output:
[07/26/2022-11:52:06] [I] === Build Options ===
[07/26/2022-11:52:06] [I] Max batch: explicit batch
[07/26/2022-11:52:06] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[07/26/2022-11:52:06] [I] minTiming: 1
[07/26/2022-11:52:06] [I] avgTiming: 8
[07/26/2022-11:52:06] [I] Precision: FP32
[07/26/2022-11:52:06] [I] LayerPrecisions: 
[07/26/2022-11:52:06] [I] Calibration: 
[07/26/2022-11:52:06] [I] Refit: Disabled
[07/26/2022-11:52:06] [I] Sparsity: Disabled
[07/26/2022-11:52:06] [I] Safe mode: Disabled
[07/26/2022-11:52:06] [I] DirectIO mode: Disabled
[07/26/2022-11:52:06] [I] Restricted mode: Disabled
[07/26/2022-11:52:06] [I] Build only: Disabled
[07/26/2022-11:52:06] [I] Save engine: converted_new.trt
[07/26/2022-11:52:06] [I] Load engine: 
[07/26/2022-11:52:06] [I] Profiling verbosity: 0
[07/26/2022-11:52:06] [I] Tactic sources: Using default tactic sources
[07/26/2022-11:52:06] [I] timingCacheMode: local
[07/26/2022-11:52:06] [I] timingCacheFile: 
[07/26/2022-11:52:06] [I] Input(s)s format: fp32:CHW
[07/26/2022-11:52:06] [I] Output(s)s format: fp32:CHW
[07/26/2022-11:52:06] [I] Input build shapes: model
[07/26/2022-11:52:06] [I] Input calibration shapes: model
[07/26/2022-11:52:06] [I] === System Options ===
[07/26/2022-11:52:06] [I] Device: 0
[07/26/2022-11:52:06] [I] DLACore: 
[07/26/2022-11:52:06] [I] Plugins:
[07/26/2022-11:52:06] [I] === Inference Options ===
[07/26/2022-11:52:06] [I] Batch: Explicit
[07/26/2022-11:52:06] [I] Input inference shapes: model
[07/26/2022-11:52:06] [I] Iterations: 10
[07/26/2022-11:52:06] [I] Duration: 3s (+ 200ms warm up)
[07/26/2022-11:52:06] [I] Sleep time: 0ms
[07/26/2022-11:52:06] [I] Idle time: 0ms
[07/26/2022-11:52:06] [I] Streams: 1
[07/26/2022-11:52:06] [I] ExposeDMA: Disabled
[07/26/2022-11:52:06] [I] Data transfers: Enabled
[07/26/2022-11:52:06] [I] Spin-wait: Disabled
[07/26/2022-11:52:06] [I] Multithreading: Disabled
[07/26/2022-11:52:06] [I] CUDA Graph: Enabled
[07/26/2022-11:52:06] [I] Separate profiling: Disabled
[07/26/2022-11:52:06] [I] Time Deserialize: Disabled
[07/26/2022-11:52:06] [I] Time Refit: Disabled
[07/26/2022-11:52:06] [I] Inputs:
[07/26/2022-11:52:06] [I] === Reporting Options ===
[07/26/2022-11:52:06] [I] Verbose: Disabled
[07/26/2022-11:52:06] [I] Averages: 10 inferences
[07/26/2022-11:52:06] [I] Percentile: 99
[07/26/2022-11:52:06] [I] Dump refittable layers:Disabled
[07/26/2022-11:52:06] [I] Dump output: Disabled
[07/26/2022-11:52:06] [I] Profile: Disabled
[07/26/2022-11:52:06] [I] Export timing to JSON file: 
[07/26/2022-11:52:06] [I] Export output to JSON file: 
[07/26/2022-11:52:06] [I] Export profile to JSON file: 
[07/26/2022-11:52:06] [I] 
[07/26/2022-11:52:06] [I] === Device Information ===
[07/26/2022-11:52:06] [I] Selected Device: Tesla V100-DGXS-32GB
[07/26/2022-11:52:06] [I] Compute Capability: 7.0
[07/26/2022-11:52:06] [I] SMs: 80
[07/26/2022-11:52:06] [I] Compute Clock Rate: 1.53 GHz
[07/26/2022-11:52:06] [I] Device Global Memory: 32505 MiB
[07/26/2022-11:52:06] [I] Shared Memory per SM: 96 KiB
[07/26/2022-11:52:06] [I] Memory Bus Width: 4096 bits (ECC enabled)
[07/26/2022-11:52:06] [I] Memory Clock Rate: 0.877 GHz
[07/26/2022-11:52:06] [I] 
[07/26/2022-11:52:06] [I] TensorRT version: 8.4.1
[07/26/2022-11:52:07] [I] [TRT] [MemUsageChange] Init CUDA: CPU +270, GPU +0, now: CPU 278, GPU 3577 (MiB)
[07/26/2022-11:52:08] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +136, GPU +46, now: CPU 433, GPU 3623 (MiB)
[07/26/2022-11:52:08] [I] Start parsing network model
[07/26/2022-11:52:08] [I] [TRT] ----------------------------------------------------------------
[07/26/2022-11:52:08] [I] [TRT] Input filename:   converted_new.onnx
[07/26/2022-11:52:08] [I] [TRT] ONNX IR version:  0.0.7
[07/26/2022-11:52:08] [I] [TRT] Opset version:    9
[07/26/2022-11:52:08] [I] [TRT] Producer name:    pytorch
[07/26/2022-11:52:08] [I] [TRT] Producer version: 1.10
[07/26/2022-11:52:08] [I] [TRT] Domain:           
[07/26/2022-11:52:08] [I] [TRT] Model version:    0
[07/26/2022-11:52:08] [I] [TRT] Doc string:       
[07/26/2022-11:52:08] [I] [TRT] ----------------------------------------------------------------
[07/26/2022-11:52:08] [W] [TRT] onnx2trt_utils.cpp:369: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[07/26/2022-11:52:08] [I] [TRT] No importer registered for op: ResizeNearest_TRT. Attempting to import as plugin.
[07/26/2022-11:52:08] [I] [TRT] Searching for plugin: ResizeNearest_TRT, plugin_version: 1, plugin_namespace: 
[07/26/2022-11:52:08] [I] [TRT] Successfully created plugin: ResizeNearest_TRT
[07/26/2022-11:52:08] [I] [TRT] No importer registered for op: ResizeNearest_TRT. Attempting to import as plugin.
[07/26/2022-11:52:08] [I] [TRT] Searching for plugin: ResizeNearest_TRT, plugin_version: 1, plugin_namespace: 
[07/26/2022-11:52:08] [I] [TRT] Successfully created plugin: ResizeNearest_TRT
[07/26/2022-11:52:08] [I] [TRT] No importer registered for op: ResizeNearest_TRT. Attempting to import as plugin.
[07/26/2022-11:52:08] [I] [TRT] Searching for plugin: ResizeNearest_TRT, plugin_version: 1, plugin_namespace: 
[07/26/2022-11:52:08] [I] [TRT] Successfully created plugin: ResizeNearest_TRT
[07/26/2022-11:52:08] [I] [TRT] No importer registered for op: EfficientNMS_TRT. Attempting to import as plugin.
[07/26/2022-11:52:08] [I] [TRT] Searching for plugin: EfficientNMS_TRT, plugin_version: 1, plugin_namespace: 
[07/26/2022-11:52:08] [I] [TRT] Successfully created plugin: EfficientNMS_TRT
[07/26/2022-11:52:08] [I] [TRT] No importer registered for op: PyramidROIAlign_TRT. Attempting to import as plugin.
[07/26/2022-11:52:08] [I] [TRT] Searching for plugin: PyramidROIAlign_TRT, plugin_version: 1, plugin_namespace: 
[07/26/2022-11:52:08] [W] [TRT] builtin_op_importers.cpp:4716: Attribute roi_coords_plusone not found in plugin node! Ensure that the plugin creator has a default value defined or the engine may fail to build.
[07/26/2022-11:52:08] [W] [TRT] builtin_op_importers.cpp:4716: Attribute legacy not found in plugin node! Ensure that the plugin creator has a default value defined or the engine may fail to build.
[07/26/2022-11:52:08] [I] [TRT] Successfully created plugin: PyramidROIAlign_TRT
[07/26/2022-11:52:08] [I] [TRT] No importer registered for op: EfficientNMS_TRT. Attempting to import as plugin.
[07/26/2022-11:52:08] [I] [TRT] Searching for plugin: EfficientNMS_TRT, plugin_version: 1, plugin_namespace: 
[07/26/2022-11:52:08] [I] [TRT] Successfully created plugin: EfficientNMS_TRT
[07/26/2022-11:52:08] [I] [TRT] No importer registered for op: PyramidROIAlign_TRT. Attempting to import as plugin.
[07/26/2022-11:52:08] [I] [TRT] Searching for plugin: PyramidROIAlign_TRT, plugin_version: 1, plugin_namespace: 
[07/26/2022-11:52:08] [W] [TRT] builtin_op_importers.cpp:4716: Attribute roi_coords_plusone not found in plugin node! Ensure that the plugin creator has a default value defined or the engine may fail to build.
[07/26/2022-11:52:08] [W] [TRT] builtin_op_importers.cpp:4716: Attribute legacy not found in plugin node! Ensure that the plugin creator has a default value defined or the engine may fail to build.
[07/26/2022-11:52:08] [I] [TRT] Successfully created plugin: PyramidROIAlign_TRT
[07/26/2022-11:52:08] [I] Finish parsing network model
[07/26/2022-11:52:10] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +385, GPU +178, now: CPU 996, GPU 3801 (MiB)
[07/26/2022-11:52:10] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +117, GPU +54, now: CPU 1113, GPU 3855 (MiB)
[07/26/2022-11:52:10] [W] [TRT] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0
[07/26/2022-11:52:10] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[07/26/2022-11:53:18] [I] [TRT] Detected 1 inputs and 5 output network tensors.
[07/26/2022-11:53:19] [I] [TRT] Total Host Persistent Memory: 157744
[07/26/2022-11:53:19] [I] [TRT] Total Device Persistent Memory: 10673152
[07/26/2022-11:53:19] [I] [TRT] Total Scratch Memory: 100352000
[07/26/2022-11:53:19] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 50 MiB, GPU 16984 MiB
[07/26/2022-11:53:19] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 43.8395ms to assign 14 blocks to 141 nodes requiring 424486408 bytes.
[07/26/2022-11:53:19] [I] [TRT] Total Activation Memory: 424486408
[07/26/2022-11:53:19] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1578, GPU 4285 (MiB)
[07/26/2022-11:53:19] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 1578, GPU 4295 (MiB)
[07/26/2022-11:53:19] [W] [TRT] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0
[07/26/2022-11:53:19] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +1, GPU +238, now: CPU 1, GPU 238 (MiB)
[07/26/2022-11:53:19] [W] [TRT] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
[07/26/2022-11:53:19] [W] [TRT] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
[07/26/2022-11:53:19] [I] Engine built in 72.9211 sec.
[07/26/2022-11:53:19] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 1491, GPU 3997 (MiB)
[07/26/2022-11:53:19] [I] [TRT] Loaded engine size: 227 MiB
[07/26/2022-11:53:19] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 1493, GPU 4235 (MiB)
[07/26/2022-11:53:19] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1493, GPU 4243 (MiB)
[07/26/2022-11:53:19] [W] [TRT] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0
[07/26/2022-11:53:19] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +237, now: CPU 0, GPU 237 (MiB)
[07/26/2022-11:53:19] [I] Engine deserialized in 0.0501396 sec.
[07/26/2022-11:53:19] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1493, GPU 4245 (MiB)
[07/26/2022-11:53:19] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1493, GPU 4253 (MiB)
[07/26/2022-11:53:19] [W] [TRT] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0
[07/26/2022-11:53:19] [I] [TRT] [MemUsageChange] TensorRT-mabundle installaged allocation in IExecutionContext creation: CPU +0, GPU +415, now: CPU 0, GPU 652 (MiB)
[07/26/2022-11:53:19] [I] Using random values for input input_tensor
[07/26/2022-11:53:20] [I] Created input binding for input_tensor with dimensions 1x3x1344x1344
[07/26/2022-11:53:20] [I] Using random values for output num_detections_box_outputs
[07/26/2022-11:53:20] [I] Created output binding for num_detections_box_outputs with dimensions 1x1
[07/26/2022-11:53:20] [I] Using random values for output detection_boxes_box_outputs
[07/26/2022-11:53:20] [I] Created output binding for detection_boxes_box_outputs with dimensions 1x100x4
[07/26/2022-11:53:20] [I] Using random values for output detection_scores_box_outputs
[07/26/2022-11:53:20] [I] Created output binding for detection_scores_box_outputs with dimensions 1x100
[07/26/2022-11:53:20] [I] Using random values for output detection_classes_box_outputs
[07/26/2022-11:53:20] [I] Created output binding for detection_classes_box_outputs with dimensions 1x100
[07/26/2022-11:53:20] [I] Using random values for output detection_masks
[07/26/2022-11:53:20] [I] Created output binding for detection_masks with dimensions 1x100x28x28
[07/26/2022-11:53:20] [I] Starting inference
[07/26/2022-11:53:23] [I] Warmup completed 4 queries over 200 ms
[07/26/2022-11:53:23] [I] Timing trace has 73 queries over 3.14073 s
[07/26/2022-11:53:23] [I] 
[07/26/2022-11:53:23] [I] === Trace details ===
[07/26/2022-11:53:23] [I] Trace averages of 10 runs:
[07/26/2022-11:53:23] [I] Average on 10 runs - GPU latency: 42.3539 ms - Host latency: 44.2657 ms (enqueue 0.0978744 ms)
[07/26/2022-11:53:23] [I] Average on 10 runs - GPU latency: 42.32 ms - Host latency: 44.2304 ms (enqueue 0.100208 ms)
[07/26/2022-11:53:23] [I] Average on 10 runs - GPU latency: 42.4947 ms - Host latency: 44.4127 ms (enqueue 0.111646 ms)
[07/26/2022-11:53:23] [I] Average on 10 runs - GPU latency: 42.5185 ms - Host latency: 44.4297 ms (enqueue 0.103748 ms)
[07/26/2022-11:53:23] [I] Average on 10 runs - GPU latency: 42.5398 ms - Host latency: 44.4519 ms (enqueue 0.0979858 ms)
[07/26/2022-11:53:23] [I] Average on 10 runs - GPU latency: 42.4066 ms - Host latency: 44.3235 ms (enqueue 0.103271 ms)
[07/26/2022-11:53:23] [I] Average on 10 runs - GPU latency: 42.5031 ms - Host latency: 44.4144 ms (enqueue 0.0985596 ms)
[07/26/2022-11:53:23] [I] 
[07/26/2022-11:53:23] [I] === Performance summary ===
[07/26/2022-11:53:23] [I] Throughput: 23.243 qps
[07/26/2022-11:53:23] [I] Latency: min = 44.1772 ms, max = 44.6904 ms, mean = 44.3555 ms, median = 44.304 ms, percentile(99%) = 44.6904 ms
[07/26/2022-11:53:23] [I] Enqueue Time: min = 0.0705566 ms, max = 0.182251 ms, mean = 0.101059 ms, median = 0.0956421 ms, percentile(99%) = 0.182251 ms
[07/26/2022-11:53:23] [I] H2D Latency: min = 1.84766 ms, max = 1.89319 ms, mean = 1.8632 ms, median = 1.86157 ms, percentile(99%) = 1.89319 ms
[07/26/2022-11:53:23] [I] GPU Compute Time: min = 42.2523 ms, max = 42.7805 ms, mean = 42.4428 ms, median = 42.3936 ms, percentile(99%) = 42.7805 ms
[07/26/2022-11:53:23] [I] D2H Latency: min = 0.0349121 ms, max = 0.0541992 ms, mean = 0.0494861 ms, median = 0.0493774 ms, percentile(99%) = 0.0541992 ms
[07/26/2022-11:53:23] [I] Total Host Walltime: 3.14073 s
[07/26/2022-11:53:23] [I] Total GPU Compute Time: 3.09833 s
[07/26/2022-11:53:23] [I] Explanations of the performance metrics are printed in the verbose logs.
[07/26/2022-11:53:23] [I] 
```
